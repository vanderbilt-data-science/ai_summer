{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2a28162-8f3e-42f8-83f6-1b9ef38cd394",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/vanderbilt-data-science/ai_summer/blob/main/2_2-solns-langchain-rag.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "# AI Solutions with Langchain and RAG\n",
    "> For Vanderbilt University AI Summer 2024<br>Prepared by Dr. Charreau Bell\n",
    "\n",
    "_Code versions applicable: May 14, 2024_\n",
    "\n",
    "## Learning Outcomes:\n",
    "* Participants will be able to articulate the essential steps and components of a retrieval-augmented generation (RAG) system and implement a standard RAG system using langchain.\n",
    "* Participants will gain familiarity in inspecting the execution pathways of LLM-based systems.\n",
    "* Participants will gain familiarity in approaches for the evaluation of LLM-based systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1cebcf-1ac1-48aa-b998-9f0b2a77567f",
   "metadata": {},
   "source": [
    "### Computing Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15202e4f-5a92-4231-a557-43daa913beb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain==0.1.20 langchain_openai grandalf sentence-transformers\n",
    "! pip install pypdf chromadb faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8f69f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best practice is to do all imports at the beginning of the notebook, but we have separated them here for learning purposes.\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e06178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# auth replicated here for reference just in case you choose to do something similar\n",
    "from google.colab import userdata\n",
    "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88934c0a-c340-4678-be23-563a4fe331f1",
   "metadata": {},
   "source": [
    "## Langchain Introduction\n",
    "\n",
    "### Overview of System\n",
    "\n",
    "[Overview of Langchain](https://python.langchain.com/v0.1/docs/get_started/introduction/)\n",
    "\n",
    "<figure>\n",
    "<img src='https://python.langchain.com/v0.1/svg/langchain_stack.svg' height=600/>\n",
    "    <figcaption>\n",
    "        Langchain Overview, from <a href=https://python.langchain.com/v0.1/docs/get_started/introduction>Langchain Introduction</a>\n",
    "    </figcaption>\n",
    "</figure>\n",
    "\n",
    "### Quick Start\n",
    "To, as it says - start quickly - get started using the [Quick Start](https://python.langchain.com/v0.1/docs/get_started/quickstart/) page.\n",
    "\n",
    "### Details of Individual Composition Components\n",
    "To learn more about any of the individual components used below, use the [Components Page](https://python.langchain.com/v0.1/docs/modules/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477bff1b",
   "metadata": {},
   "source": [
    "## Review of python formatted strings\n",
    "To prepare ourselves for langchain, we'll first review formatted strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cff2bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me a story about cats\n",
      "As string  Tell me a story about cats\n",
      "With formatted string: Tell me a story about cats\n"
     ]
    }
   ],
   "source": [
    "# basic functionality of print\n",
    "print('Tell me a story about cats')\n",
    "\n",
    "# with variables\n",
    "prompt_string = 'Tell me a story about cats'\n",
    "print('As string ', prompt_string)\n",
    "\n",
    "# as formatted string\n",
    "prompt_string = 'Tell me a story about cats'\n",
    "print(f\"With formatted string: {prompt_string}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d708c91c",
   "metadata": {},
   "source": [
    "Motivating example: you are building a GPT that tells stories. The user just needs to provide the topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd22772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a story about {topic}'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as a template string\n",
    "string_prompt_template = f\"Tell me a story about {{topic}}\"\n",
    "string_prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e55c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a story about cats'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can fill in the template at a later time\n",
    "string_prompt_template.format(topic='cats')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7ffaf4",
   "metadata": {},
   "source": [
    "## Langchain Prompt Templates\n",
    "> Formatting and arranging prompt strings\n",
    "\n",
    "Langchain prompt templates work just like this, but with additional functionality targeted towards LLM interaction. There are lots of different prompt templates, but here, we'll focus on two: `PromptTemplate`, and `ChatPromptTemplate`.\n",
    "\n",
    "**Additional resources**: [Guide on Prompt Templates](https://python.langchain.com/v0.1/docs/modules/model_io/prompts/quick_start/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f3192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3a0cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create system messsage for shorter responses\n",
    "brief_system_message = 'You are a helpful assistant. Be brief, succinct, and clear in your responses. Only answer what is asked.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f581ae79",
   "metadata": {},
   "source": [
    "### PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dda49b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='tell me a story about cats')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a langchain prompt template\n",
    "lc_prompt = PromptTemplate.from_template(\"tell me a story about {topic}\")\n",
    "\n",
    "# has standard behavior of f-strings\n",
    "lc_prompt.format(topic='cats')\n",
    "\n",
    "# but also has additional functionality\n",
    "lc_prompt.invoke({'topic':'cats'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38033eec",
   "metadata": {},
   "source": [
    "### ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f253a330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='tell me a story about cats')])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create prompt template\n",
    "lc_chat_prompt_template = ChatPromptTemplate.from_template(\"tell me a story about {topic}\")\n",
    "\n",
    "# has invocation functionality resulting to chat-style messages\n",
    "lc_chat_prompt_template.invoke({'topic':'cats'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6896b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful assistant. Be brief, succinct, and clear in your responses. Only answer what is asked.'), HumanMessage(content='Tell me a story about cats')])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create message-based chat prompt template\n",
    "lc_chat_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', brief_system_message),\n",
    "        ('user', 'Tell me a story about {topic}'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# invoke the chat prompt template\n",
    "lc_chat_prompt_template.invoke({'topic':'cats'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20703088",
   "metadata": {},
   "source": [
    "## Langchain Expression Language (LCEL)\n",
    "**Resource:** [LCEL Overview](https://python.langchain.com/v0.1/docs/expression_language/)\n",
    "Main Points:\n",
    "* Runnable Protocol\n",
    "* Known inputs and outputs on invoke\n",
    "* Flexibility in chain assembly\n",
    "* [Standard Interface](https://python.langchain.com/v0.1/docs/expression_language/interface/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2D0GyPPpedXw",
   "metadata": {},
   "source": [
    "# Basic Model Chains/ Model I/O\n",
    "\n",
    "**Resource**: [Detailed Guide](https://python.langchain.com/v0.1/docs/modules/)\n",
    "\n",
    "## Basic Prompt/Model Chain\n",
    "See [Prompt+LLM](https://python.langchain.com/docs/expression_language/cookbook/prompt_llm_parser) for more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d1b35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f068a62-9a56-420a-be6f-2bf3bb805d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"tell me a joke about {foo}\")\n",
    "model = ChatOpenAI()\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1GVTTau0fsdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='tell me a joke about cats')])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observe what the prompt looks like when we substitute words into it\n",
    "prompt.invoke({'foo':\"cats\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VP7khR3zd2OJ",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Why was the cat sitting on the computer?\\n\\nBecause it wanted to keep an eye on the mouse!' response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 13, 'total_tokens': 33}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-a30ceed4-66f1-41f7-8ef3-df9501ed0158-0'\n"
     ]
    }
   ],
   "source": [
    "# Now, actually call the entire chain on it\n",
    "res = chain.invoke({'foo':\"cats\"})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d753e10d",
   "metadata": {},
   "source": [
    "A little helper visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dc608a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    +-------------+    \n",
      "    | PromptInput |    \n",
      "    +-------------+    \n",
      "           *           \n",
      "           *           \n",
      "           *           \n",
      "+--------------------+ \n",
      "| ChatPromptTemplate | \n",
      "+--------------------+ \n",
      "           *           \n",
      "           *           \n",
      "           *           \n",
      "    +------------+     \n",
      "    | ChatOpenAI |     \n",
      "    +------------+     \n",
      "           *           \n",
      "           *           \n",
      "           *           \n",
      " +------------------+  \n",
      " | ChatOpenAIOutput |  \n",
      " +------------------+  \n"
     ]
    }
   ],
   "source": [
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LUCuzx2HfeVx",
   "metadata": {},
   "source": [
    "## Even more simplified prompt chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eM3wDIpnfg3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create total user prompt chain\n",
    "prompt = ChatPromptTemplate.from_template(\"{text}\")\n",
    "\n",
    "# Add output parser\n",
    "chain = prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8hStGS1kfonX",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4: A New Hope - Luke Skywalker joins forces with Princess Leia, Han Solo, and Obi-Wan Kenobi to defeat the evil Galactic Empire and destroy the Death Star.\n",
      "\n",
      "Episode 5: The Empire Strikes Back - The Empire launches an attack on the Rebel Alliance, leading to a climactic battle on the ice planet Hoth. Luke trains with Yoda to become a Jedi, while Darth Vader reveals he is Luke's father.\n",
      "\n",
      "Episode 6: Return of the Jedi - Luke confronts Darth Vader and Emperor Palpatine in an attempt to turn his father back to the light side of the Force. The Rebel Alliance defeats the Empire in the Battle of Endor, leading to the downfall of the Sith and the redemption of Anakin Skywalker.\n"
     ]
    }
   ],
   "source": [
    "# Now, the user can submit literally whatever\n",
    "res = chain.invoke({'text':\"Briefly and succintly summarize Episodes 4-6 of Star Wars.\"})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958be68e",
   "metadata": {},
   "source": [
    "## What just happened? Inspecting model behavior\n",
    "Several ways to do this:\n",
    "* `langchain` verbosity/debugging\n",
    "* `langsmith`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9684a3",
   "metadata": {},
   "source": [
    "### Langchain\n",
    "Resource: [Guides -> Langchain Debugging](https://python.langchain.com/v0.1/docs/guides/development/debugging/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76bf06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_debug, set_verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88edac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_debug(True)\n",
    "set_verbose(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1984a1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What is a python f-string?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What is a python f-string?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: What is a python f-string?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [2.19s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"An f-string is a way to format strings in Python, introduced in Python 3.6. It allows for easier string interpolation by embedding variables directly into the string itself. To create an f-string, simply prefix the string with 'f' or 'F' and place the variables inside curly braces within the string. Here's an example:\\n\\n```python\\nname = \\\"Alice\\\"\\nage = 30\\nf_string = f\\\"My name is {name} and I am {age} years old.\\\"\\nprint(f_string)\\n```\\n\\nThis will output:\\n```\\nMy name is Alice and I am 30 years old.\\n```\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"An f-string is a way to format strings in Python, introduced in Python 3.6. It allows for easier string interpolation by embedding variables directly into the string itself. To create an f-string, simply prefix the string with 'f' or 'F' and place the variables inside curly braces within the string. Here's an example:\\n\\n```python\\nname = \\\"Alice\\\"\\nage = 30\\nf_string = f\\\"My name is {name} and I am {age} years old.\\\"\\nprint(f_string)\\n```\\n\\nThis will output:\\n```\\nMy name is Alice and I am 30 years old.\\n```\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 126,\n",
      "                \"prompt_tokens\": 14,\n",
      "                \"total_tokens\": 140\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-8b5adb0e-200a-474a-ab5e-c53c773d82d8-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 126,\n",
      "      \"prompt_tokens\": 14,\n",
      "      \"total_tokens\": 140\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"An f-string is a way to format strings in Python, introduced in Python 3.6. It allows for easier string interpolation by embedding variables directly into the string itself. To create an f-string, simply prefix the string with 'f' or 'F' and place the variables inside curly braces within the string. Here's an example:\\n\\n```python\\nname = \\\"Alice\\\"\\nage = 30\\nf_string = f\\\"My name is {name} and I am {age} years old.\\\"\\nprint(f_string)\\n```\\n\\nThis will output:\\n```\\nMy name is Alice and I am 30 years old.\\n```\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [2.20s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"An f-string is a way to format strings in Python, introduced in Python 3.6. It allows for easier string interpolation by embedding variables directly into the string itself. To create an f-string, simply prefix the string with 'f' or 'F' and place the variables inside curly braces within the string. Here's an example:\\n\\n```python\\nname = \\\"Alice\\\"\\nage = 30\\nf_string = f\\\"My name is {name} and I am {age} years old.\\\"\\nprint(f_string)\\n```\\n\\nThis will output:\\n```\\nMy name is Alice and I am 30 years old.\\n```\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'An f-string is a way to format strings in Python, introduced in Python 3.6. It allows for easier string interpolation by embedding variables directly into the string itself. To create an f-string, simply prefix the string with \\'f\\' or \\'F\\' and place the variables inside curly braces within the string. Here\\'s an example:\\n\\n```python\\nname = \"Alice\"\\nage = 30\\nf_string = f\"My name is {name} and I am {age} years old.\"\\nprint(f_string)\\n```\\n\\nThis will output:\\n```\\nMy name is Alice and I am 30 years old.\\n```'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic prompt -> model -> parser chain\n",
    "chain = prompt | model | StrOutputParser()\n",
    "chain.invoke('What is a python f-string?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e60883c",
   "metadata": {},
   "source": [
    "### Langsmith\n",
    "Resource: [Tracing Langchain with Langsmith](https://docs.smith.langchain.com/how_to_guides/tracing/trace_with_langchain)\n",
    "\n",
    "Don't have a langsmith API Key yet? You'll need a user account on [Langsmith](https://smith.langchain.com/). Then, follow these [instructions provided by langsmith](https://docs.smith.langchain.com/#2-create-an-api-key)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6948026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset this\n",
    "set_debug(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e427ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable tracing and set project name\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = \"false\"\n",
    "\n",
    "# uncomment the following two lines before running the cell if you have a Langchain/Langsmith API Key\n",
    "#os.environ['LANGCHAIN_API_KEY'] = userdata.get('LANGCHAIN_API_KEY')\n",
    "#os.environ['LANGCHAIN_TRACING_V2'] = \"true\"\n",
    "\n",
    "# set langchain project\n",
    "os.environ['LANGCHAIN_PROJECT'] = 'May15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9e76df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"An f-string is a formatted string literal in Python, introduced in Python 3.6. It allows for easy interpolation of variables and expressions inside a string by prefixing the string with 'f' or 'F' and using curly braces {} to insert the variables or expressions. This makes it easier to create readable and concise strings with embedded variables.\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# use a the basic chain from above\n",
    "chain = (prompt | model | StrOutputParser()).with_config(run_name = 'Basic LLM Chain')\n",
    "response = chain.invoke(\"What is a python f-string?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d4399e",
   "metadata": {},
   "source": [
    "#### View langsmith traces\n",
    "We can take a look at this trace on [Langsmith](https://smith.langchain.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545b8841",
   "metadata": {},
   "source": [
    "## Adding Memory\n",
    "Adapted from: [LCEL Adding Message History](https://python.langchain.com/v0.1/docs/expression_language/how_to/message_history/)\n",
    "Also see:\n",
    "- [Langchain -> Use Cases -> Chatbots -> Memory Management](https://python.langchain.com/v0.1/docs/use_cases/chatbots/memory_management/)\n",
    "- [Components -> More -> Memory](https://python.langchain.com/v0.1/docs/modules/memory/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0873b34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9843f11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create chat template with standard elements\n",
    "model = ChatOpenAI(name='gpt-3.5-turbo')\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", brief_system_message),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{most_recent_user_message}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "turns_chain = prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b39d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The humor in that joke comes from the unexpected behavior of cats jumping on beds, which is a common occurrence for cat owners.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quickly try out chain, pretending we've already said something to the system\n",
    "first_chat_turn_messages = [(\"human\", \"Tell me a joke about cats\"),\n",
    "                            (\"ai\", \"Cats jump on beds\")]\n",
    "\n",
    "next_user_message = \"What was funny about that joke?\"\n",
    "turns_chain.invoke({'most_recent_user_message': next_user_message,\n",
    "                    'chat_history': first_chat_turn_messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f37fa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all saved conversations\n",
    "chat_conversation_threads = {}\n",
    "\n",
    "# define function to create new conversation or load old one based on session_id\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in chat_conversation_threads:\n",
    "        chat_conversation_threads[session_id] = ChatMessageHistory()\n",
    "    return chat_conversation_threads[session_id]\n",
    "\n",
    "# create chat history enabled chain\n",
    "chat_with_message_history = RunnableWithMessageHistory(\n",
    "    turns_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"most_recent_user_message\",\n",
    "    history_messages_key=\"chat_history\", \n",
    ").with_config(run_name = 'Chat with Message History')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac18605",
   "metadata": {},
   "source": [
    "Let's try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076cfa99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 6cb7b7e8-a725-4f9c-9937-37106c5b25cf not found for run 65b5cfa7-c7e1-4676-a3c3-6311973eed63. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Sure! Why was the cat sitting on the computer? Because it wanted to keep an eye on the mouse!'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# send first message\n",
    "user_message_1 = \"Tell me a joke about cats\"\n",
    "session_id_1 = \"convo_1\"\n",
    "chat_with_message_history.invoke({'most_recent_user_message': user_message_1},\n",
    "                                config={\"configurable\": {\"session_id\": session_id_1}})        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441d9331",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 1330fff0-1590-4365-aa1d-135c05d3f2b8 not found for run 3eb0b3a7-258d-4083-b5da-a109a10ee9fd. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'In the joke, the cat sits on the computer to watch the \"mouse,\" which can refer to both the computer mouse and the small rodent. It\\'s a play on words that adds humor to the situation.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# send second message\n",
    "chat_with_message_history.invoke({'most_recent_user_message': \"I don't get it - can you explain?\"},\n",
    "                                    config={\"configurable\": {\"session_id\": session_id_1}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47da336f",
   "metadata": {},
   "source": [
    "#### View langsmith traces\n",
    "We can take a look at this trace on [Langsmith](https://smith.langchain.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j-T1I1nDiM-A",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation (RAG)\n",
    "## Review\n",
    "* Conceptual and step-by-step guide about [RAG](https://python.langchain.com/v0.1/docs/use_cases/question_answering/)\n",
    "* Learn more about implementing [RAG](https://python.langchain.com/docs/expression_language/cookbook/retrieval)\n",
    "\n",
    "**Data Ingestion (Creating a Vector Store of Documents)**\n",
    "<figure>\n",
    "<img src='https://python.langchain.com/v0.1/assets/images/rag_indexing-8160f90a90a33253d0154659cf7d453f.png' height=300/>\n",
    "    <figcaption>\n",
    "        Source: Data Ingestion (Preparing Embeddings), from <a href=https://python.langchain.com/v0.1/docs/use_cases/question_answering/>Langchain Use Case: Q&A with RAG</a>\n",
    "    </figcaption>\n",
    "</figure>\n",
    "\n",
    "**Retrieval and Generation**\n",
    "<figure>\n",
    "<img src='https://python.langchain.com/v0.1/assets/images/rag_retrieval_generation-1046a4668d6bb08786ef73c56d4f228a.png' height=300/>\n",
    "    <figcaption>\n",
    "        Source: Retrieval and Generation, from <a href=https://python.langchain.com/v0.1/docs/use_cases/question_answering/>Langchain Use Case: Q&A with RAG</a>\n",
    "    </figcaption>\n",
    "</figure>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HOs-D7XQlmzt",
   "metadata": {},
   "source": [
    "## Document Loaders and Splitters\n",
    "[Data Ingestion/Vector Store Preparation Guide ](https://python.langchain.com/docs/modules/data_connection/)\n",
    "<figure>\n",
    "<img src='https://python.langchain.com/v0.1/assets/images/data_connection-95ff2033a8faa5f3ba41376c0f6dd32a.jpg' height=300/>\n",
    "    <figcaption>\n",
    "        Langchain Retrieval Component, from <a href=https://python.langchain.com/docs/modules/data_connection/>Langchain Components</a>\n",
    "    </figcaption>\n",
    "</figure>\n",
    "\n",
    "**Other extremely useful resources**:\n",
    "* **[Components -> Retrieval -> Document Loaders](https://python.langchain.com/v0.1/docs/modules/data_connection/document_loaders/)**: Use the sidebar to navigate through different types of document loaders. For all available integrations available through langchain, see [Components -> Integrations -> Components](https://python.langchain.com/v0.1/docs/integrations/document_loaders/)\n",
    "* **[Components -> Retrieval -> Text Splitters](https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/)**: Use the sidebar to navigate through different types of text splitters. For all available integrations available through langchain, see [Components -> Integrations -> Components](https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cf0508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example pdf links\n",
    "doc_1 = 'https://registrar.vanderbilt.edu/documents/Undergraduate_School_Catalog_2023-24_UPDATED2.pdf'\n",
    "doc_2 = 'https://www.tnmd.uscourts.gov/sites/tnmd/files/Pro%20Se%20Nonprisoner%20Handbook.pdf'\n",
    "doc_3 = 'https://www.uscis.gov/sites/default/files/document/guides/M-654.pdf'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aff93e",
   "metadata": {},
   "source": [
    "### Example: pdfloader and recursive character splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Sk4B1Ihklod8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31d1836",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(doc_3)\n",
    "\n",
    "# Add the kind of text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=250,\n",
    ")\n",
    "\n",
    "# use the text splitter to split the document\n",
    "chunks = loader.load_and_split(text_splitter=text_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9490d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138\n"
     ]
    }
   ],
   "source": [
    "# see how many chunks were made\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e3261f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='The Declaration of \\nIndependence \\n& the  \\nConstitution  \\nof the United States\\nM-654 (rev. 07/08)', metadata={'source': 'https://www.uscis.gov/sites/default/files/document/guides/M-654.pdf', 'page': 0})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect a single chunk\n",
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ab1136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Chunk 0 ******\n",
      "The Declaration of \n",
      "Independence \n",
      "& the  \n",
      "Constitution  \n",
      "of the United States\n",
      "M-654 (rev. 07/08)\n",
      "\n",
      "****** Chunk 1 ******\n",
      "The Declaration of \n",
      "Independence \n",
      "& the  \n",
      "Constitution  \n",
      "of the United States\n",
      "\n",
      "****** Chunk 2 ******\n",
      "“The sacred rights of mankind are not to be \n",
      "rummaged for, among old parchments, or musty \n",
      "records. They are written, as with a sun beam \n",
      "in the whole volume of human nature, by the \n",
      "hand of the divinity itself; and can never be \n",
      "erased or obscured by mortal power. ” \n",
      "— Alexander Hamilton, 1775\n",
      "“The basis of our political systems is the \n",
      "right of the people to make and to alter \n",
      "their Constitutions of Government. But the \n",
      "Constitution which at any time exists, ‘till \n",
      "changed by an explicit and authentic act of the \n",
      "whole People is sacredly obligatory upon all. ”\n",
      "— George Washington, 1796\n",
      "“The Declaration of Independence...[is the] \n",
      "declaratory charter of our rights, and of the \n",
      "rights of man. ” \n",
      "— Thomas Jefferson, 1819MeSSage froM The DIreCT or \n",
      "The Declaration of Independence and the\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view first 3 chunks\n",
    "for chunk_index, chunk in enumerate(chunks[:3]):\n",
    "    print(f'****** Chunk {chunk_index} ******\\n{chunk.page_content}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fd5bbb",
   "metadata": {},
   "source": [
    "### Example: Loading website data and splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f15b971",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import SoupStrainer\n",
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa1ea14",
   "metadata": {},
   "outputs": [],
   "source": [
    "constitution_website = \"https://constitutioncenter.org/the-constitution/full-text\"\n",
    "\n",
    "# load using WebBaseLoader\n",
    "web_loader = WebBaseLoader(constitution_website,\n",
    "                       bs_kwargs = {'parse_only':SoupStrainer(['article'])})\n",
    "\n",
    "# read the document from the website (without splitting)\n",
    "web_document = web_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c754f1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "We the People of the United States, in Order to form a more perfect Union, establish Justice, insure domestic Tranquility, provide for the common defence, promote the general Welfare, and secure the Blessings of Liberty to ourselves and our Posterity, do ordain and establish this Constitution for the United States of America.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# only the first few characters\n",
    "print(web_document[0].page_content[:330])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330f96da",
   "metadata": {},
   "source": [
    "Now, we'll split in a slightly different way. Since we've already scraped the website, we will just directly use the splitter. Note that after we load the website, we have a data type of (list of) `Document`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15cfb1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "website_splitter = RecursiveCharacterTextSplitter(chunk_size=330, chunk_overlap=100, add_start_index=True)\n",
    "website_chunks = website_splitter.split_documents(web_document)\n",
    "len(website_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f581f865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='We the People of the United States, in Order to form a more perfect Union, establish Justice, insure domestic Tranquility, provide for the common defence, promote the general Welfare, and secure the Blessings of Liberty to ourselves and our Posterity, do ordain and establish this Constitution for the United States of America.', metadata={'source': 'https://constitutioncenter.org/the-constitution/full-text', 'start_index': 1}),\n",
       " Document(page_content='Section 1: Congress\\nAll legislative Powers herein granted shall be vested in a Congress of the United States, which shall consist of a Senate and House of Representatives.', metadata={'source': 'https://constitutioncenter.org/the-constitution/full-text', 'start_index': 330}),\n",
       " Document(page_content='Section 2: The House of Representatives\\nThe House of Representatives shall be composed of Members chosen every second Year by the People of the several States, and the Electors in each State shall have the Qualifications requisite for Electors of the most numerous Branch of the State Legislature.', metadata={'source': 'https://constitutioncenter.org/the-constitution/full-text', 'start_index': 503})]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "website_chunks[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841ab566",
   "metadata": {},
   "source": [
    "If you know less about the constitution and more about Star wars (or another topic available on Wikipedia), feel free to run the cells below to use that text moving forward. It will replace the `website_chunks` variable. You may need to adjust the `chunk_size` and `chunk_overlap` options. Uncomment and run these cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bb3ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks generated:  17\n",
      "\n",
      "\n",
      "Sample: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='From Simple English Wikipedia, the free encyclopedia', metadata={'source': 'https://simple.wikipedia.org/wiki/Star_Wars_Episode_IV:_A_New_Hope', 'start_index': 4}),\n",
       " Document(page_content='Star Wars: Episode IV -A New HopeSpecial Edition LogoDirected byGeorge LucasWritten byGeorge LucasProduced byGary KurtzRick McCallum(Special Edition)StarringMark HamillHarrison FordCarrie FisherPeter CushingAlec GuinnessCinematographyGilbert Taylor, BSCEdited byRichard ChewPaul HirschMarcia LucasMusic byJohn WilliamsDistributed by20th Century FoxLucasfilmRelease datesMay 25, 1977 (USA)October 27, 1977 (Australia)December 27, 1977 (UK)Running time121 minutes (original)125 minutes (Special', metadata={'source': 'https://simple.wikipedia.org/wiki/Star_Wars_Episode_IV:_A_New_Hope', 'start_index': 59}),\n",
       " Document(page_content='27, 1977 (Australia)December 27, 1977 (UK)Running time121 minutes (original)125 minutes (Special Edition)CountryUnited StatesLanguageEnglish Budget$11,000,000', metadata={'source': 'https://simple.wikipedia.org/wiki/Star_Wars_Episode_IV:_A_New_Hope', 'start_index': 455}),\n",
       " Document(page_content=\"Star Wars: Episode IV: A New Hope (initially named Star Wars) is a science fiction movie. It is the first film made in the Star Wars saga, but is the fourth film in the story's timeline. The movie was released in 1977 and also incorporates adventure, action and drama.\", metadata={'source': 'https://simple.wikipedia.org/wiki/Star_Wars_Episode_IV:_A_New_Hope', 'start_index': 614}),\n",
       " Document(page_content=\"Plot[change | change source]\\nThe film takes place years after Revenge of the Sith, which was made in 2005 as a prequel. The Rebellion has stolen the secret plans for the Galactic Empire's superweapon known as the Death Star. Darth Vader and his stormtroopers capture Princess Leia Organa, a leader of the Rebellion but she secretly gives the Death Star plans to two droids (robots), C-3PO and R2-D2.\", metadata={'source': 'https://simple.wikipedia.org/wiki/Star_Wars_Episode_IV:_A_New_Hope', 'start_index': 885})]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alternate data\n",
    "webloader = WebBaseLoader('https://simple.wikipedia.org/wiki/Star_Wars_Episode_IV:_A_New_Hope',\n",
    "                       bs_kwargs = {'parse_only':SoupStrainer('div', id='bodyContent')})\n",
    "web_chunks = webloader.load_and_split(RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100, add_start_index=True))\n",
    "print('Number of chunks generated: ', len(web_chunks))\n",
    "print('\\n\\nSample: ')\n",
    "web_chunks[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mKdzgo6ci0MD",
   "metadata": {},
   "source": [
    "## Vector Stores: A way to store embeddings (hidden states) of your data\n",
    "The choice of vector store influences how \"relevant\" documents can be identified, speed of document retrieval, and organization.\n",
    "\n",
    "Helpful resources:\n",
    "* **[Brief Langchain Reference](https://python.langchain.com/v0.1/docs/modules/data_connection/vectorstores/)**\n",
    "* **[Vector Store Integrations](https://python.langchain.com/v0.1/docs/integrations/vectorstores/)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2831d1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jmXDTgoqjCUs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the vector store\n",
    "db = Chroma.from_documents(web_chunks, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217d27ea",
   "metadata": {},
   "source": [
    "### Similarity Search for Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XC-5zEeioFmq",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Star Wars: Episode IV: A New Hope (initially named Star Wars) is a science fiction movie. It is the first film made in the Star Wars saga, but is the fourth film in the story's timeline. The movie was released in 1977 and also incorporates adventure, action and drama.\", metadata={'source': 'https://simple.wikipedia.org/wiki/Star_Wars_Episode_IV:_A_New_Hope', 'start_index': 614}),\n",
       " Document(page_content='Star Wars: Episode IV -A New HopeSpecial Edition LogoDirected byGeorge LucasWritten byGeorge LucasProduced byGary KurtzRick McCallum(Special Edition)StarringMark HamillHarrison FordCarrie FisherPeter CushingAlec GuinnessCinematographyGilbert Taylor, BSCEdited byRichard ChewPaul HirschMarcia LucasMusic byJohn WilliamsDistributed by20th Century FoxLucasfilmRelease datesMay 25, 1977 (USA)October 27, 1977 (Australia)December 27, 1977 (UK)Running time121 minutes (original)125 minutes (Special', metadata={'source': 'https://simple.wikipedia.org/wiki/Star_Wars_Episode_IV:_A_New_Hope', 'start_index': 59}),\n",
       " Document(page_content='This short article about movies can be made longer. You can help Wikipedia by adding to it.\\n\\n\\n\\n\\nRetrieved from \"https://simple.wikipedia.org/w/index.php?title=Star_Wars_Episode_IV:_A_New_Hope&oldid=9535375\"\\nCategories: English-language movies1977 science fiction movies20th Century Fox moviesMovies directed by George LucasScreenplays by George LucasStar Wars Skywalker Saga moviesUnited States National Film Registry moviesHidden category: Movie stubs', metadata={'source': 'https://simple.wikipedia.org/wiki/Star_Wars_Episode_IV:_A_New_Hope', 'start_index': 4360}),\n",
       " Document(page_content='Official website\\nStar Wars Episode IV: A New Hope on IMDb\\nStar Wars Episode IV: A New Hope at AllMovie\\nStar Wars at the Movie Wiki', metadata={'source': 'https://simple.wikipedia.org/wiki/Star_Wars_Episode_IV:_A_New_Hope', 'start_index': 3769})]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query the vector store\n",
    "query = 'When was a new hope released?'\n",
    "\n",
    "# use a similarity search between the vectors\n",
    "relevant_docs = db.similarity_search(query)\n",
    "relevant_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1c197d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content=\"Star Wars: Episode IV: A New Hope (initially named Star Wars) is a science fiction movie. It is the first film made in the Star Wars saga, but is the fourth film in the story's timeline. The movie was released in 1977 and also incorporates adventure, action and drama.\", metadata={'source': 'https://simple.wikipedia.org/wiki/Star_Wars_Episode_IV:_A_New_Hope', 'start_index': 614}),\n",
       "  0.2804918587207794),\n",
       " (Document(page_content='Star Wars: Episode IV -A New HopeSpecial Edition LogoDirected byGeorge LucasWritten byGeorge LucasProduced byGary KurtzRick McCallum(Special Edition)StarringMark HamillHarrison FordCarrie FisherPeter CushingAlec GuinnessCinematographyGilbert Taylor, BSCEdited byRichard ChewPaul HirschMarcia LucasMusic byJohn WilliamsDistributed by20th Century FoxLucasfilmRelease datesMay 25, 1977 (USA)October 27, 1977 (Australia)December 27, 1977 (UK)Running time121 minutes (original)125 minutes (Special', metadata={'source': 'https://simple.wikipedia.org/wiki/Star_Wars_Episode_IV:_A_New_Hope', 'start_index': 59}),\n",
       "  0.2861720025539398),\n",
       " (Document(page_content='This short article about movies can be made longer. You can help Wikipedia by adding to it.\\n\\n\\n\\n\\nRetrieved from \"https://simple.wikipedia.org/w/index.php?title=Star_Wars_Episode_IV:_A_New_Hope&oldid=9535375\"\\nCategories: English-language movies1977 science fiction movies20th Century Fox moviesMovies directed by George LucasScreenplays by George LucasStar Wars Skywalker Saga moviesUnited States National Film Registry moviesHidden category: Movie stubs', metadata={'source': 'https://simple.wikipedia.org/wiki/Star_Wars_Episode_IV:_A_New_Hope', 'start_index': 4360}),\n",
       "  0.30957573652267456),\n",
       " (Document(page_content='Official website\\nStar Wars Episode IV: A New Hope on IMDb\\nStar Wars Episode IV: A New Hope at AllMovie\\nStar Wars at the Movie Wiki', metadata={'source': 'https://simple.wikipedia.org/wiki/Star_Wars_Episode_IV:_A_New_Hope', 'start_index': 3769}),\n",
       "  0.3343406319618225)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get cosine distance alongside results\n",
    "relevant_docs = db.similarity_search_with_score(query)\n",
    "relevant_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CWJwyByyhoSB",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content=\"Star Wars: Episode IV: A New Hope (initially named Star Wars) is a science fiction movie. It is the first film made in the Star Wars saga, but is the fourth film in the story's timeline. The movie was released in 1977 and also incorporates adventure, action and drama.\", metadata={'source': 'https://simple.wikipedia.org/wiki/Star_Wars_Episode_IV:_A_New_Hope', 'start_index': 614}),\n",
       "  0.8113249121939496),\n",
       " (Document(page_content=\"Plot[change | change source]\\nThe film takes place years after Revenge of the Sith, which was made in 2005 as a prequel. The Rebellion has stolen the secret plans for the Galactic Empire's superweapon known as the Death Star. Darth Vader and his stormtroopers capture Princess Leia Organa, a leader of the Rebellion but she secretly gives the Death Star plans to two droids (robots), C-3PO and R2-D2.\", metadata={'source': 'https://simple.wikipedia.org/wiki/Star_Wars_Episode_IV:_A_New_Hope', 'start_index': 885}),\n",
       "  0.8017252298757446),\n",
       " (Document(page_content='Wikiquote has a collection of quotations related to: Star Wars Episode IV: A New Hope', metadata={'source': 'https://simple.wikipedia.org/wiki/Star_Wars_Episode_IV:_A_New_Hope', 'start_index': 3682}),\n",
       "  0.7943083749887673),\n",
       " (Document(page_content='This short article about movies can be made longer. You can help Wikipedia by adding to it.\\n\\n\\n\\n\\nRetrieved from \"https://simple.wikipedia.org/w/index.php?title=Star_Wars_Episode_IV:_A_New_Hope&oldid=9535375\"\\nCategories: English-language movies1977 science fiction movies20th Century Fox moviesMovies directed by George LucasScreenplays by George LucasStar Wars Skywalker Saga moviesUnited States National Film Registry moviesHidden category: Movie stubs', metadata={'source': 'https://simple.wikipedia.org/wiki/Star_Wars_Episode_IV:_A_New_Hope', 'start_index': 4360}),\n",
       "  0.7871477518673119)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another query, but instead use normalized score\n",
    "query = 'What is the plot of A New Hope?'\n",
    "relevant_docs = db.similarity_search_with_relevance_scores(query)\n",
    "relevant_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lt_uoYfLjUdx",
   "metadata": {},
   "source": [
    "## Retrievers: How we select the most relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KTNxqQf7kiY_",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Star Wars: Episode IV: A New Hope (initially named Star Wars) is a science fiction movie. It is the first film made in the Star Wars saga, but is the fourth film in the story's timeline. The movie was released in 1977 and also incorporates adventure, action and drama.\", metadata={'source': 'https://simple.wikipedia.org/wiki/Star_Wars_Episode_IV:_A_New_Hope', 'start_index': 614}),\n",
       " Document(page_content=\"Plot[change | change source]\\nThe film takes place years after Revenge of the Sith, which was made in 2005 as a prequel. The Rebellion has stolen the secret plans for the Galactic Empire's superweapon known as the Death Star. Darth Vader and his stormtroopers capture Princess Leia Organa, a leader of the Rebellion but she secretly gives the Death Star plans to two droids (robots), C-3PO and R2-D2.\", metadata={'source': 'https://simple.wikipedia.org/wiki/Star_Wars_Episode_IV:_A_New_Hope', 'start_index': 885}),\n",
       " Document(page_content='Wikiquote has a collection of quotations related to: Star Wars Episode IV: A New Hope', metadata={'source': 'https://simple.wikipedia.org/wiki/Star_Wars_Episode_IV:_A_New_Hope', 'start_index': 3682}),\n",
       " Document(page_content='This short article about movies can be made longer. You can help Wikipedia by adding to it.\\n\\n\\n\\n\\nRetrieved from \"https://simple.wikipedia.org/w/index.php?title=Star_Wars_Episode_IV:_A_New_Hope&oldid=9535375\"\\nCategories: English-language movies1977 science fiction movies20th Century Fox moviesMovies directed by George LucasScreenplays by George LucasStar Wars Skywalker Saga moviesUnited States National Film Registry moviesHidden category: Movie stubs', metadata={'source': 'https://simple.wikipedia.org/wiki/Star_Wars_Episode_IV:_A_New_Hope', 'start_index': 4360})]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or use the db as a retriever with lcel\n",
    "retriever = db.as_retriever()\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8IuaToUPc0Hy",
   "metadata": {},
   "source": [
    "## RAG\n",
    "For when we want to actually do generation, but want there to be retrieved documents included in the generation. For this, we're going to switch to a different embedding model which will be downloaded on our machine (or if on Google Colab, there)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3298219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough, RunnableSequence, RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f952c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Star Wars: Episode IV: A New Hope (initially named Star Wars) is a science fiction movie. It is the first film made in the Star Wars saga, but is the fourth film in the story's timeline. The movie was released in 1977 and also incorporates adventure, action and drama.\", metadata={'source': 'https://simple.wikipedia.org/wiki/Star_Wars_Episode_IV:_A_New_Hope', 'start_index': 614})]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use different embedding model\n",
    "embeddings_fn = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\") #, model_kwargs={\"device\":'mps'})\n",
    "hf_db = FAISS.from_documents(web_chunks, embeddings_fn)\n",
    "hf_retriever = hf_db.as_retriever(search_kwargs={\"k\":1})\n",
    "\n",
    "# make sure it works\n",
    "query = 'What is the plot of A New Hope?'\n",
    "hf_retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cb408b",
   "metadata": {},
   "source": [
    "### Default RAG: Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Fsewtgf9alyl",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic question answering template\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "# compose prompt\n",
    "rag_prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# create model (so we don't have to depend on the model definition at the top of the notebook)\n",
    "model = ChatOpenAI(model_name='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ExSC1rNNmCw",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to format the retrieved documents better\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([f'Reference text:\\n{doc.page_content}\\n\\Citation Info: {doc.metadata}' for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73636824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Reference text:\\nFrom Simple English Wikipedia, the free encyclopedia\\n\\\\Citation Info: {'source': 'https://simple.wikipedia.org/wiki/Star_Wars_Episode_IV:_A_New_Hope', 'start_index': 4}\\n\\nReference text:\\nStar Wars: Episode IV -A New HopeSpecial Edition LogoDirected byGeorge LucasWritten byGeorge LucasProduced byGary KurtzRick McCallum(Special Edition)StarringMark HamillHarrison FordCarrie FisherPeter CushingAlec GuinnessCinematographyGilbert Taylor, BSCEdited byRichard ChewPaul HirschMarcia LucasMusic byJohn WilliamsDistributed by20th Century FoxLucasfilmRelease datesMay 25, 1977 (USA)October 27, 1977 (Australia)December 27, 1977 (UK)Running time121 minutes (original)125 minutes (Special\\n\\\\Citation Info: {'source': 'https://simple.wikipedia.org/wiki/Star_Wars_Episode_IV:_A_New_Hope', 'start_index': 59}\\n\\nReference text:\\n27, 1977 (Australia)December 27, 1977 (UK)Running time121 minutes (original)125 minutes (Special Edition)CountryUnited StatesLanguageEnglish Budget$11,000,000\\n\\\\Citation Info: {'source': 'https://simple.wikipedia.org/wiki/Star_Wars_Episode_IV:_A_New_Hope', 'start_index': 455}\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect behavior of format_docs\n",
    "format_docs(web_chunks[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21071aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compose the chain\n",
    "rag_chain = (\n",
    "    {\"context\": hf_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cba6e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The plot of \"A New Hope\" follows the journey of Luke Skywalker, a young farm boy who discovers his destiny as a Jedi Knight after obtaining a message from Princess Leia asking for help in the rebellion against the evil Galactic Empire. With the help of Han Solo and Obi-Wan Kenobi, Luke sets out to rescue Princess Leia and ultimately destroy the Empire\\'s powerful weapon, the Death Star.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the chain\n",
    "rag_chain.with_config(run_name = 'basic_rag_chain').invoke('What is the plot of a new hope')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c99c95",
   "metadata": {},
   "source": [
    "### RAG with Sources\n",
    "Resource: [Langchain: Returning Sources](https://python.langchain.com/v0.1/docs/use_cases/question_answering/sources/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47c733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdb371f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic prompt -> model -> parser chain\n",
    "single_turn_chain = (\n",
    "    rag_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Break previous chain in half to access context and question in returned response\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": hf_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=single_turn_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b36d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: Reference text:\n",
      "Plot[change | change source]\n",
      "The film takes place years after Revenge of the Sith, which was made in 2005 as a prequel. The Rebellion has stolen the secret plans for the Galactic Empire's superweapon known as the Death Star. Darth Vader and his stormtroopers capture Princess Leia Organa, a leader of the Rebellion but she secretly gives the Death Star plans to two droids (robots), C-3PO and R2-D2.\n",
      "\\Citation Info: {'source': 'https://simple.wikipedia.org/wiki/Star_Wars_Episode_IV:_A_New_Hope', 'start_index': 885}\n",
      "\n",
      "question: What happened to Princess Leia in a New Hope?\n",
      "\n",
      "answer: Princess Leia was captured by Darth Vader and his stormtroopers, but she secretly gave the Death Star plans to two droids, C-3PO and R2-D2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# invoke\n",
    "response = rag_chain_with_source.with_config(run_name = 'sources_rag_chain').invoke(\"What happened to Princess Leia in a New Hope?\")\n",
    "\n",
    "# print full response\n",
    "for key, value in response.items():\n",
    "    print(f\"{key}: {value}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afec178a",
   "metadata": {},
   "source": [
    "### RAG with Chat History?\n",
    "\n",
    "We will have a one-turn system with our RAG system. How do we add chat memory? See below for implementation guides:\n",
    "- [Use cases: Q&A with Rag: Add Chat History.](https://python.langchain.com/v0.1/docs/use_cases/question_answering/chat_history/)  Builds on a RAG system, so will be of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d3434e",
   "metadata": {},
   "source": [
    "## LLM System Metrics\n",
    "Resource: [Guides -> Evaluation](https://python.langchain.com/v0.1/docs/guides/productionization/evaluation/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92372d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation import load_evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bac358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure what we want to evaluate\n",
    "rs_question = \"What happened to Princess Leia in a New Hope?\"\n",
    "rs_answer = rag_chain.with_config(run_name = 'basic_rag_chain').invoke(rs_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da42e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new CriteriaEvalChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are assessing a submitted answer on a given task or input based on a set of criteria. Here is the data:\n",
      "[BEGIN DATA]\n",
      "***\n",
      "[Input]: What happened to Princess Leia in a New Hope?\n",
      "***\n",
      "[Submission]: Princess Leia was captured by Darth Vader and his stormtroopers in A New Hope.\n",
      "***\n",
      "[Criteria]: conciseness: Is the submission concise and to the point?\n",
      "***\n",
      "[END DATA]\n",
      "Does the submission meet the Criteria? First, write out in a step by step manner your reasoning about each criterion to be sure that your conclusion is correct. Avoid simply stating the correct answers at the outset. Then print only the single character \"Y\" or \"N\" (without quotes or punctuation) on its own line corresponding to the correct answer of whether the submission meets all criteria. At the end, repeat just the letter again by itself on a new line.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'reasoning': '1. **Review the Submission**: The submission states, \"Princess Leia was captured by Darth Vader and his stormtroopers in A New Hope.\"\\n\\n2. **Understanding the Criterion - Conciseness**: The criterion of conciseness demands that the response should be direct, with no unnecessary details or filler words. It should directly address the question without veering off-topic.\\n\\n3. **Analyzing the Submission Against the Criterion**:\\n   - The phrase \"Princess Leia was captured by Darth Vader and his stormtroopers\" is a succinct description of Leia\\'s primary situation in \"A New Hope.\"\\n   - The submission does not include any excessive details or extraneous information that deviates from the answer required by the question.\\n   - The answer is directly related to the question asked about Leia\\'s fate in the movie.\\n\\n4. **Conclusion**: The submission directly answers what happened to Princess Leia in \"A New Hope\" by stating the key event (her capture) without adding unnecessary details. Therefore, it meets the criterion of conciseness.\\n\\nY',\n",
       " 'value': 'Y',\n",
       " 'score': 1}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load an evaluator that uses the conciseness criteria\n",
    "evaluator = load_evaluator(\"criteria\", criteria=\"conciseness\", llm=ChatOpenAI(model_name='gpt-4-turbo'))\n",
    "\n",
    "# evaluate whether our model was concise or not\n",
    "eval_result = evaluator.evaluate_strings(\n",
    "    prediction = rs_answer,\n",
    "    input = rs_question,\n",
    ")\n",
    "\n",
    "# print result\n",
    "eval_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933a5e2e",
   "metadata": {},
   "source": [
    "View other criteria available through LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dbb810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Criteria.CONCISENESS: 'conciseness'>,\n",
       " <Criteria.RELEVANCE: 'relevance'>,\n",
       " <Criteria.CORRECTNESS: 'correctness'>,\n",
       " <Criteria.COHERENCE: 'coherence'>,\n",
       " <Criteria.HARMFULNESS: 'harmfulness'>,\n",
       " <Criteria.MALICIOUSNESS: 'maliciousness'>,\n",
       " <Criteria.HELPFULNESS: 'helpfulness'>,\n",
       " <Criteria.CONTROVERSIALITY: 'controversiality'>,\n",
       " <Criteria.MISOGYNY: 'misogyny'>,\n",
       " <Criteria.CRIMINALITY: 'criminality'>,\n",
       " <Criteria.INSENSITIVITY: 'insensitivity'>,\n",
       " <Criteria.DEPTH: 'depth'>,\n",
       " <Criteria.CREATIVITY: 'creativity'>,\n",
       " <Criteria.DETAIL: 'detail'>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.evaluation import Criteria\n",
    "list(Criteria)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ea2044",
   "metadata": {},
   "source": [
    "# Homework\n",
    "The following exercises are designed to help you gain depth in what you've learned about RAG today.\n",
    "\n",
    "## [Required] Learning more about RAG\n",
    "### Splitting Text (Conceptual)\n",
    "There are so many ways to split the text, and each has an impact on the resultant RAG system. Below is a resource (with sidebar dropdown) for you to read over and then answer the following question for the text splitting approaches (as relevant to your application):\n",
    "* What is the proposed value in adopting this text splitting approach? What are some drawbacks?\n",
    "\n",
    "### Splitting Text (Programmatic)\n",
    "Above, we have adopted specific chunk sizes and splitting approaches. Choose one of the documents (or use your own) and:\n",
    "* Modify the chunk size. How does this impact the resulting RAG performance? The cost?\n",
    "* Implement a different type of text splitter (as applicable, i.e., not code text splitters if you're not splitting code). How does this impact the resulting RAG performance? The cost?\n",
    "\n",
    "### Customizing RAG\n",
    "There are many, many, many ways to improve results with RAG. Below are some resources for you to read over then complete the following:\n",
    "1. What is the proposed value in adopting this approach? In other words, what is the expected performance improvement by using this method?\n",
    "2. How might it apply to your work?\n",
    "\n",
    "* [**Query Analysis**](https://python.langchain.com/v0.1/docs/use_cases/query_analysis/). Make sure to peruse subtopics.\n",
    "* [**Synthetic Data Generation**](https://python.langchain.com/v0.1/docs/use_cases/data_generation/). \n",
    "* [**Tagging**](https://python.langchain.com/v0.1/docs/use_cases/tagging/).\n",
    "* [**Routing Chain Logic Based on inputs****](https://python.langchain.com/v0.1/docs/expression_language/how_to/routing/). \n",
    "* [**Chain Composition**](https://python.langchain.com/v0.1/docs/modules/chains/). Of particular interest here are the Legacy chains. Although they will probably be completely removed in the future, consider their behavior. In what cases might these behaviors be useful?\n",
    "\n",
    "** This is highly recommended reading, but may not be suitable for those who are novices in programming. Although there is text, the code demonstrates concretely by the text. For novices, it may be better to copy/paste the code as well to understand the behavior, although it is noted that such a task may be outside of the the time constraints of for some participants.\n",
    "\n",
    "## [Required] Learning more about Evaluation\n",
    "Read the following text and answer these questions:\n",
    "1. What is the purpose of the individual criterion? Does it require and external LLM for evaluation?\n",
    "2. In what cases might this criteria be useful?\n",
    "\n",
    "Depth Text: [**Evaluation, by Langchain**](https://python.langchain.com/v0.1/docs/guides/productionization/evaluation/)\n",
    "\n",
    "## [Highly recommended] Learning more about the LLM System Lifecycle\n",
    "There is more to an LLM-based system than a user interface and the LLM chain. There is a whole framework around inspecting, testing, and evaluating these systems. Read the following and answer the questions below:\n",
    "1. Summarize the purpose of the individual components of the langsmith system (they generalize to all LLM systems).\n",
    "2. Consider your favorite LLM UI (i.e., ChatGPT, Gemini, Claude, etc). Describe how you think these components are utilized the LLM system.\n",
    "\n",
    "Depth Text: [**LangSmith User Guide**](https://docs.smith.langchain.com/old/user_guide)\n",
    "\n",
    "## [Recommended] Practicing with RAG and Langchain\n",
    "### Exercise 1: Modify the RAG system\n",
    "Modify or create a new chain which:\n",
    "1. Uses a different LLM than the one used in this notebook.\n",
    "2. Uses a different document loader\n",
    "3. Uses a different splitter than the one used in this notebook.\n",
    "4. Uses a different vector store/retriever than the one used in this notebook.\n",
    "\n",
    "Use the resources provided in the relevant sections of the notebook for other options.\n",
    "\n",
    "### Exercise 2: Implement a new RAG system\n",
    "1. [More challenging] Add chat history to one of your RAG chains. Make sure to enable tracing and inspect langsmith to ensure that the chat history is used.\n",
    "2. Create a gradio user interface to use your chain in a more user-friendly way.\n",
    "3. [Challenging] Implement an additional chain which uses one of the strategies you read about in the \"Learning more about RAG\" section.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0cdb4ccb06c1499e9714b81a255993d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16a18b98a5f54513b79aa3618ea6736e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fff6c8d96fa541e6aa5370dc37390cec",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_94162c2e8de94850b3da21e898ae3e9e",
      "value": 3
     }
    },
    "1f35015f30164fa3becb2b142d933cd6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "31dd85caa7434f9b9a7cbec22140b0e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f4788fa6efa644a8b0c08c2f7026df22",
      "placeholder": "​",
      "style": "IPY_MODEL_3cb1ff1c69ee4ad89dc4f8848b4f24a6",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "3cb1ff1c69ee4ad89dc4f8848b4f24a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "94162c2e8de94850b3da21e898ae3e9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9e6e1c4e60114b249e4ced3a81e87f7f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9fa2070bbbbc477c886b8569244cfc20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0cdb4ccb06c1499e9714b81a255993d2",
      "placeholder": "​",
      "style": "IPY_MODEL_1f35015f30164fa3becb2b142d933cd6",
      "value": " 3/3 [00:03&lt;00:00,  1.07s/it]"
     }
    },
    "ad13e58f69fe45efb8e617bdb429463b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_31dd85caa7434f9b9a7cbec22140b0e4",
       "IPY_MODEL_16a18b98a5f54513b79aa3618ea6736e",
       "IPY_MODEL_9fa2070bbbbc477c886b8569244cfc20"
      ],
      "layout": "IPY_MODEL_9e6e1c4e60114b249e4ced3a81e87f7f"
     }
    },
    "f4788fa6efa644a8b0c08c2f7026df22": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fff6c8d96fa541e6aa5370dc37390cec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
